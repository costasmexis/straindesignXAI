{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "\n",
    "FILE = '../data/carotene/data_random_pool.mat'\n",
    "ENZYMES = ['E', 'I', 'YB']\n",
    "TARGET = ['prod']\n",
    "\n",
    "def data_to_df(file: str) -> pd.DataFrame:\n",
    "    \"\"\" Load data from .mat file and convert to pandas DataFrame\"\"\"\n",
    "    data = loadmat(file)\n",
    "    df = pd.DataFrame(data['TrainingSet'], columns=ENZYMES + TARGET)\n",
    "    df[ENZYMES] = df[ENZYMES].round(4)\n",
    "    return df\n",
    "\n",
    "def get_enzyme_levels(df: pd.DataFrame) -> list:\n",
    "    \"\"\" Get all unique values in the columns in the list \"\"\"\n",
    "    unique_values = []\n",
    "    for col in ENZYMES:\n",
    "        unique_values += df[col].unique().tolist()\n",
    "    return np.unique(unique_values)\n",
    "\n",
    "def create_comb_space(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Create a combination space for all unique values in the columns in the list \"\"\"\n",
    "    enzyme_levels = get_enzyme_levels(df)\n",
    "    comb_space = pd.DataFrame(np.array(np.meshgrid(*[enzyme_levels]*3)).T.reshape(-1, 3), columns=ENZYMES)\n",
    "    return comb_space\n",
    "\n",
    "def linlog_transformation(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    \"\"\" Perform linlog transformation on the columns in the list \"\"\"\n",
    "    log_data = np.log10(df[columns])\n",
    "    scaled_data = 2 * (log_data - log_data.min()) / (log_data.max() - log_data.min()) - 1\n",
    "    return scaled_data\n",
    "\n",
    "def target_normalization(df: pd.DataFrame, target: str, SCALE: float = 0.7) -> pd.DataFrame:\n",
    "    \"\"\" Normalize the target column \"\"\"\n",
    "    df[target] = (df[target] - df[target].min()) / (df[target].max() - df[target].min())\n",
    "    df[target] = df[target] * SCALE\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique enzyme levels: 10\n"
     ]
    }
   ],
   "source": [
    "df = data_to_df(FILE)\n",
    "comb_space = create_comb_space(df)\n",
    "\n",
    "ENZYME_LEVELS = get_enzyme_levels(df)\n",
    "print(f'Number of unique enzyme levels: {len(ENZYME_LEVELS)}')\n",
    "\n",
    "df_scaled = linlog_transformation(df, ENZYMES).round(2)\n",
    "comb_space_scaled = linlog_transformation(comb_space, ENZYMES).round(2)\n",
    "\n",
    "df = target_normalization(df, 'prod')\n",
    "\n",
    "# From comb_space_scaled remove rows that are in df_scaled\n",
    "comb_space_scaled = comb_space_scaled[~comb_space_scaled.isin(df_scaled)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X_train, y_train and X_test\n",
    "X_train = df_scaled[ENZYMES].values\n",
    "y_train = df[TARGET].values.ravel()\n",
    "\n",
    "X_test = comb_space_scaled[ENZYMES].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 12:14:03.969301: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-20 12:14:03.972819: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-20 12:14:04.009895: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-20 12:14:04.009929: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-20 12:14:04.009967: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-20 12:14:04.018825: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-20 12:14:04.019186: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 12:14:04.828559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 0.0999 - val_loss: 0.0908\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0870 - val_loss: 0.0744\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0754 - val_loss: 0.0599\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0653 - val_loss: 0.0473\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0565 - val_loss: 0.0366\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0492 - val_loss: 0.0278\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0432 - val_loss: 0.0209\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0385 - val_loss: 0.0156\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0350 - val_loss: 0.0118\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0326 - val_loss: 0.0093\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0310 - val_loss: 0.0080\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0302 - val_loss: 0.0075\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0298 - val_loss: 0.0075\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0297 - val_loss: 0.0079\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0298 - val_loss: 0.0084\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0298 - val_loss: 0.0089\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0297 - val_loss: 0.0092\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0293 - val_loss: 0.0093\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0288 - val_loss: 0.0092\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0280 - val_loss: 0.0089\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0270 - val_loss: 0.0084\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0259 - val_loss: 0.0077\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0248 - val_loss: 0.0070\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0237 - val_loss: 0.0063\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0226 - val_loss: 0.0056\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0217 - val_loss: 0.0050\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0209 - val_loss: 0.0045\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0203 - val_loss: 0.0042\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0198 - val_loss: 0.0039\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0194 - val_loss: 0.0037\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0192 - val_loss: 0.0036\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0191 - val_loss: 0.0035\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0191 - val_loss: 0.0034\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0190 - val_loss: 0.0034\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0190 - val_loss: 0.0033\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0190 - val_loss: 0.0032\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0189 - val_loss: 0.0031\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0188 - val_loss: 0.0030\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0186 - val_loss: 0.0029\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0184 - val_loss: 0.0029\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0182 - val_loss: 0.0028\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0181 - val_loss: 0.0028\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0179 - val_loss: 0.0028\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0177 - val_loss: 0.0029\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0176 - val_loss: 0.0030\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0175 - val_loss: 0.0031\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0175 - val_loss: 0.0033\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0174 - val_loss: 0.0035\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0174 - val_loss: 0.0036\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0174 - val_loss: 0.0038\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0174 - val_loss: 0.0039\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0174 - val_loss: 0.0040\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0174 - val_loss: 0.0040\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0174 - val_loss: 0.0040\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0174 - val_loss: 0.0039\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0174 - val_loss: 0.0039\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0174 - val_loss: 0.0038\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0173 - val_loss: 0.0037\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0173 - val_loss: 0.0035\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0173 - val_loss: 0.0034\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0172 - val_loss: 0.0033\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0172 - val_loss: 0.0032\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0172 - val_loss: 0.0031\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0172 - val_loss: 0.0031\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0172 - val_loss: 0.0030\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0172 - val_loss: 0.0030\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0172 - val_loss: 0.0030\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0172 - val_loss: 0.0030\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0172 - val_loss: 0.0030\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0172 - val_loss: 0.0030\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0171 - val_loss: 0.0031\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0171 - val_loss: 0.0031\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0171 - val_loss: 0.0032\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0171 - val_loss: 0.0032\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0171 - val_loss: 0.0033\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0171 - val_loss: 0.0034\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0171 - val_loss: 0.0035\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0171 - val_loss: 0.0036\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0170 - val_loss: 0.0036\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0170 - val_loss: 0.0037\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0170 - val_loss: 0.0037\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0170 - val_loss: 0.0038\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0170 - val_loss: 0.0038\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0170 - val_loss: 0.0039\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0170 - val_loss: 0.0039\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0170 - val_loss: 0.0039\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0170 - val_loss: 0.0039\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0170 - val_loss: 0.0039\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0170 - val_loss: 0.0039\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0170 - val_loss: 0.0039\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0170 - val_loss: 0.0038\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0170 - val_loss: 0.0038\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0170 - val_loss: 0.0038\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0169 - val_loss: 0.0038\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0169 - val_loss: 0.0038\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0169 - val_loss: 0.0038\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0169 - val_loss: 0.0039\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0169 - val_loss: 0.0039\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0169 - val_loss: 0.0039\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0169 - val_loss: 0.0039\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0169 - val_loss: 0.0039\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0169 - val_loss: 0.0040\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0169 - val_loss: 0.0040\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0169 - val_loss: 0.0040\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0169 - val_loss: 0.0040\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0169 - val_loss: 0.0041\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0167 - val_loss: 0.0041\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0166 - val_loss: 0.0041\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0165 - val_loss: 0.0040\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0165 - val_loss: 0.0040\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0165 - val_loss: 0.0040\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0165 - val_loss: 0.0040\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0165 - val_loss: 0.0040\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0165 - val_loss: 0.0040\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0165 - val_loss: 0.0040\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0165 - val_loss: 0.0040\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0165 - val_loss: 0.0039\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0165 - val_loss: 0.0038\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0165 - val_loss: 0.0038\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0165 - val_loss: 0.0038\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0165 - val_loss: 0.0038\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0165 - val_loss: 0.0038\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0165 - val_loss: 0.0038\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0164 - val_loss: 0.0038\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0164 - val_loss: 0.0038\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0164 - val_loss: 0.0038\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0164 - val_loss: 0.0038\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0164 - val_loss: 0.0038\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0164 - val_loss: 0.0038\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0164 - val_loss: 0.0038\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0164 - val_loss: 0.0038\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0164 - val_loss: 0.0038\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0164 - val_loss: 0.0036\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0164 - val_loss: 0.0036\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0164 - val_loss: 0.0036\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0164 - val_loss: 0.0036\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0164 - val_loss: 0.0036\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0164 - val_loss: 0.0036\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0163 - val_loss: 0.0036\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0163 - val_loss: 0.0036\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0163 - val_loss: 0.0036\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0163 - val_loss: 0.0036\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0163 - val_loss: 0.0036\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0163 - val_loss: 0.0036\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0163 - val_loss: 0.0034\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0163 - val_loss: 0.0034\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0163 - val_loss: 0.0034\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0163 - val_loss: 0.0034\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0163 - val_loss: 0.0034\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0163 - val_loss: 0.0034\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0163 - val_loss: 0.0034\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0162 - val_loss: 0.0034\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0162 - val_loss: 0.0034\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0162 - val_loss: 0.0034\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0162 - val_loss: 0.0032\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0162 - val_loss: 0.0032\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0162 - val_loss: 0.0032\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0162 - val_loss: 0.0032\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0162 - val_loss: 0.0032\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0162 - val_loss: 0.0032\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0162 - val_loss: 0.0032\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0162 - val_loss: 0.0032\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0161 - val_loss: 0.0032\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0161 - val_loss: 0.0031\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0161 - val_loss: 0.0031\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0161 - val_loss: 0.0031\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0161 - val_loss: 0.0031\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0161 - val_loss: 0.0031\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0161 - val_loss: 0.0031\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0161 - val_loss: 0.0031\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0161 - val_loss: 0.0031\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0161 - val_loss: 0.0030\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0161 - val_loss: 0.0030\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0161 - val_loss: 0.0030\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0161 - val_loss: 0.0030\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0161 - val_loss: 0.0030\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0161 - val_loss: 0.0030\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0161 - val_loss: 0.0030\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0160 - val_loss: 0.0030\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0160 - val_loss: 0.0029\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0160 - val_loss: 0.0029\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0160 - val_loss: 0.0029\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0160 - val_loss: 0.0029\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0160 - val_loss: 0.0029\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0160 - val_loss: 0.0029\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0160 - val_loss: 0.0029\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0160 - val_loss: 0.0029\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0160 - val_loss: 0.0028\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0160 - val_loss: 0.0028\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0160 - val_loss: 0.0028\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0160 - val_loss: 0.0028\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0160 - val_loss: 0.0028\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0159 - val_loss: 0.0028\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0159 - val_loss: 0.0028\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0159 - val_loss: 0.0027\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0159 - val_loss: 0.0027\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0159 - val_loss: 0.0027\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0159 - val_loss: 0.0027\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0159 - val_loss: 0.0027\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0159 - val_loss: 0.0027\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0159 - val_loss: 0.0027\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0159 - val_loss: 0.0026\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0159 - val_loss: 0.0026\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0159 - val_loss: 0.0026\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0158 - val_loss: 0.0026\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0158 - val_loss: 0.0026\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0158 - val_loss: 0.0026\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0158 - val_loss: 0.0026\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0158 - val_loss: 0.0025\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0158 - val_loss: 0.0025\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0158 - val_loss: 0.0025\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0158 - val_loss: 0.0025\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0158 - val_loss: 0.0025\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0158 - val_loss: 0.0025\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0158 - val_loss: 0.0025\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0157 - val_loss: 0.0024\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0157 - val_loss: 0.0024\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0157 - val_loss: 0.0024\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0157 - val_loss: 0.0024\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0157 - val_loss: 0.0024\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0157 - val_loss: 0.0024\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0157 - val_loss: 0.0024\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0157 - val_loss: 0.0023\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0157 - val_loss: 0.0023\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0157 - val_loss: 0.0023\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0156 - val_loss: 0.0023\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0156 - val_loss: 0.0023\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0156 - val_loss: 0.0023\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0156 - val_loss: 0.0022\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0156 - val_loss: 0.0022\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0156 - val_loss: 0.0022\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0156 - val_loss: 0.0022\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0156 - val_loss: 0.0022\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0156 - val_loss: 0.0022\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0155 - val_loss: 0.0022\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0155 - val_loss: 0.0021\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0155 - val_loss: 0.0021\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0155 - val_loss: 0.0021\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0155 - val_loss: 0.0021\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0155 - val_loss: 0.0021\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0155 - val_loss: 0.0021\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0155 - val_loss: 0.0020\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0154 - val_loss: 0.0020\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0154 - val_loss: 0.0020\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0154 - val_loss: 0.0020\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0154 - val_loss: 0.0020\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0154 - val_loss: 0.0020\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0154 - val_loss: 0.0019\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0154 - val_loss: 0.0019\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0153 - val_loss: 0.0019\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0153 - val_loss: 0.0019\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0153 - val_loss: 0.0019\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0153 - val_loss: 0.0019\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0153 - val_loss: 0.0019\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0153 - val_loss: 0.0018\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0153 - val_loss: 0.0018\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0152 - val_loss: 0.0018\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0152 - val_loss: 0.0018\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0152 - val_loss: 0.0018\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0152 - val_loss: 0.0018\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0152 - val_loss: 0.0017\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0152 - val_loss: 0.0017\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0151 - val_loss: 0.0017\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0151 - val_loss: 0.0017\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0151 - val_loss: 0.0017\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0151 - val_loss: 0.0017\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0151 - val_loss: 0.0016\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0151 - val_loss: 0.0016\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0150 - val_loss: 0.0016\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0150 - val_loss: 0.0016\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0150 - val_loss: 0.0016\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0150 - val_loss: 0.0016\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0150 - val_loss: 0.0016\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0149 - val_loss: 0.0015\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0149 - val_loss: 0.0015\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0149 - val_loss: 0.0015\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0149 - val_loss: 0.0015\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0149 - val_loss: 0.0015\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0148 - val_loss: 0.0015\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0148 - val_loss: 0.0014\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0148 - val_loss: 0.0014\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0148 - val_loss: 0.0014\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0148 - val_loss: 0.0014\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0147 - val_loss: 0.0014\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0147 - val_loss: 0.0014\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0147 - val_loss: 0.0014\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0147 - val_loss: 0.0013\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0147 - val_loss: 0.0013\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0146 - val_loss: 0.0013\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0146 - val_loss: 0.0013\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0146 - val_loss: 0.0013\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0146 - val_loss: 0.0013\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0145 - val_loss: 0.0013\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0145 - val_loss: 0.0012\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0145 - val_loss: 0.0012\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0145 - val_loss: 0.0012\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0144 - val_loss: 0.0012\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0144 - val_loss: 0.0012\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0144 - val_loss: 0.0012\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0144 - val_loss: 0.0012\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0143 - val_loss: 0.0011\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0143 - val_loss: 0.0011\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0143 - val_loss: 0.0011\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0143 - val_loss: 0.0011\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0142 - val_loss: 0.0011\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0142 - val_loss: 0.0011\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0142 - val_loss: 0.0011\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0142 - val_loss: 0.0010\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0141 - val_loss: 0.0010\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0141 - val_loss: 0.0010\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0141 - val_loss: 0.0010\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0141 - val_loss: 9.9008e-04\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0140 - val_loss: 9.7730e-04\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0140 - val_loss: 9.6463e-04\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0140 - val_loss: 9.5206e-04\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - val_loss: 9.3960e-04\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0139 - val_loss: 9.2726e-04\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0139 - val_loss: 9.1502e-04\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0139 - val_loss: 9.0290e-04\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0138 - val_loss: 8.9090e-04\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0138 - val_loss: 8.7901e-04\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0138 - val_loss: 8.6724e-04\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0138 - val_loss: 8.5559e-04\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0137 - val_loss: 8.4406e-04\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0137 - val_loss: 8.3265e-04\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0137 - val_loss: 8.2137e-04\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0136 - val_loss: 8.1021e-04\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0136 - val_loss: 7.9917e-04\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0136 - val_loss: 7.8828e-04\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0135 - val_loss: 7.7750e-04\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0135 - val_loss: 7.6686e-04\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0135 - val_loss: 7.5635e-04\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0135 - val_loss: 7.4596e-04\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0134 - val_loss: 7.3572e-04\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0134 - val_loss: 7.2561e-04\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0134 - val_loss: 7.1563e-04\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0133 - val_loss: 7.0580e-04\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0133 - val_loss: 6.9610e-04\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0133 - val_loss: 6.8654e-04\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0132 - val_loss: 6.7711e-04\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0132 - val_loss: 6.6784e-04\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0132 - val_loss: 6.5870e-04\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0131 - val_loss: 6.4971e-04\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0131 - val_loss: 6.4086e-04\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0131 - val_loss: 6.3215e-04\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0130 - val_loss: 6.2359e-04\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0130 - val_loss: 6.1517e-04\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0130 - val_loss: 6.0690e-04\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0129 - val_loss: 5.9878e-04\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0129 - val_loss: 5.9080e-04\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0129 - val_loss: 5.8298e-04\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0128 - val_loss: 5.7530e-04\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0128 - val_loss: 5.6778e-04\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0128 - val_loss: 5.6040e-04\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0127 - val_loss: 5.5318e-04\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0127 - val_loss: 5.4611e-04\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0127 - val_loss: 5.3918e-04\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0126 - val_loss: 5.3241e-04\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0126 - val_loss: 5.2579e-04\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0126 - val_loss: 5.1933e-04\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0125 - val_loss: 5.1301e-04\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0125 - val_loss: 5.0685e-04\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0125 - val_loss: 5.0084e-04\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0124 - val_loss: 4.9499e-04\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0124 - val_loss: 4.8929e-04\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0124 - val_loss: 4.8375e-04\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0123 - val_loss: 4.7836e-04\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0123 - val_loss: 4.7312e-04\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0123 - val_loss: 4.6804e-04\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0122 - val_loss: 4.6311e-04\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0122 - val_loss: 4.5833e-04\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0122 - val_loss: 4.5371e-04\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0122 - val_loss: 4.4925e-04\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0121 - val_loss: 4.4493e-04\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0121 - val_loss: 4.4077e-04\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0121 - val_loss: 4.3677e-04\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0120 - val_loss: 4.3292e-04\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0120 - val_loss: 4.2922e-04\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0120 - val_loss: 4.2567e-04\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0119 - val_loss: 4.2228e-04\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0119 - val_loss: 4.1904e-04\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0119 - val_loss: 4.1595e-04\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0118 - val_loss: 4.1301e-04\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0118 - val_loss: 4.1023e-04\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0118 - val_loss: 4.0759e-04\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0117 - val_loss: 4.0511e-04\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0117 - val_loss: 4.0277e-04\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0117 - val_loss: 4.0059e-04\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0116 - val_loss: 3.9855e-04\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0116 - val_loss: 3.9666e-04\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0116 - val_loss: 3.9492e-04\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0115 - val_loss: 3.9332e-04\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0115 - val_loss: 3.9188e-04\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0115 - val_loss: 3.9057e-04\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0114 - val_loss: 3.8942e-04\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0114 - val_loss: 3.8840e-04\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0114 - val_loss: 3.8753e-04\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0113 - val_loss: 3.8680e-04\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0113 - val_loss: 3.8622e-04\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0113 - val_loss: 3.8578e-04\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0112 - val_loss: 3.8547e-04\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0112 - val_loss: 3.8530e-04\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0112 - val_loss: 3.8528e-04\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0111 - val_loss: 3.8538e-04\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0111 - val_loss: 3.8563e-04\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0111 - val_loss: 3.8601e-04\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0111 - val_loss: 3.8653e-04\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0110 - val_loss: 3.8717e-04\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0110 - val_loss: 3.8795e-04\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0110 - val_loss: 3.8887e-04\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0109 - val_loss: 3.8991e-04\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0109 - val_loss: 3.9108e-04\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0109 - val_loss: 3.9237e-04\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0108 - val_loss: 3.9379e-04\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0108 - val_loss: 3.9534e-04\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0108 - val_loss: 3.9701e-04\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0108 - val_loss: 3.9880e-04\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0107 - val_loss: 4.0072e-04\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0107 - val_loss: 4.0275e-04\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0107 - val_loss: 4.0491e-04\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0106 - val_loss: 4.0718e-04\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0106 - val_loss: 4.0957e-04\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0106 - val_loss: 4.1207e-04\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0105 - val_loss: 4.1468e-04\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0105 - val_loss: 4.1741e-04\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0105 - val_loss: 4.2024e-04\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0105 - val_loss: 4.2319e-04\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0104 - val_loss: 4.2624e-04\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0104 - val_loss: 4.2940e-04\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0104 - val_loss: 4.3266e-04\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0103 - val_loss: 4.3603e-04\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0103 - val_loss: 4.3949e-04\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0103 - val_loss: 4.4306e-04\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0103 - val_loss: 4.4673e-04\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0102 - val_loss: 4.5049e-04\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0102 - val_loss: 4.5435e-04\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0102 - val_loss: 4.5830e-04\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0101 - val_loss: 4.6234e-04\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0101 - val_loss: 4.6648e-04\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0101 - val_loss: 4.7071e-04\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0101 - val_loss: 4.7502e-04\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0100 - val_loss: 4.7942e-04\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0100 - val_loss: 4.8390e-04\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0100 - val_loss: 4.8847e-04\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0100 - val_loss: 4.9311e-04\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0099 - val_loss: 4.9784e-04\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0099 - val_loss: 5.0265e-04\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0099 - val_loss: 5.0753e-04\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0099 - val_loss: 5.1249e-04\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0098 - val_loss: 5.1753e-04\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0098 - val_loss: 5.2263e-04\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0098 - val_loss: 5.2780e-04\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0097 - val_loss: 5.3305e-04\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0097 - val_loss: 5.3836e-04\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0097 - val_loss: 5.4374e-04\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0097 - val_loss: 5.4918e-04\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0096 - val_loss: 5.5469e-04\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0096 - val_loss: 5.6026e-04\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0096 - val_loss: 5.6589e-04\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0096 - val_loss: 5.7157e-04\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0095 - val_loss: 5.7732e-04\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0095 - val_loss: 5.8312e-04\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0095 - val_loss: 5.8897e-04\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0095 - val_loss: 5.9488e-04\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0094 - val_loss: 6.0084e-04\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0094 - val_loss: 6.0685e-04\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0094 - val_loss: 6.1291e-04\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0094 - val_loss: 6.1901e-04\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0093 - val_loss: 6.2516e-04\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0093 - val_loss: 6.3136e-04\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0093 - val_loss: 6.3759e-04\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0093 - val_loss: 6.4388e-04\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0092 - val_loss: 6.5020e-04\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0092 - val_loss: 6.5655e-04\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0092 - val_loss: 6.6296e-04\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0092 - val_loss: 6.6939e-04\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0091 - val_loss: 6.7586e-04\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0091 - val_loss: 6.8237e-04\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0091 - val_loss: 6.8890e-04\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0091 - val_loss: 6.9547e-04\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0090 - val_loss: 7.0208e-04\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0090 - val_loss: 7.0870e-04\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0090 - val_loss: 7.1536e-04\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0090 - val_loss: 7.2205e-04\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0089 - val_loss: 7.2876e-04\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0089 - val_loss: 7.3549e-04\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0089 - val_loss: 7.4226e-04\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0089 - val_loss: 7.4904e-04\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0088 - val_loss: 7.5584e-04\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0088 - val_loss: 7.6267e-04\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0088 - val_loss: 7.6951e-04\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0088 - val_loss: 7.7638e-04\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0088 - val_loss: 7.8326e-04\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0087 - val_loss: 7.9016e-04\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0087 - val_loss: 7.9707e-04\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0087 - val_loss: 8.0399e-04\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0087 - val_loss: 8.1094e-04\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0086 - val_loss: 8.1789e-04\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0086 - val_loss: 8.2486e-04\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0086 - val_loss: 8.3184e-04\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0086 - val_loss: 8.3883e-04\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0085 - val_loss: 8.4583e-04\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085 - val_loss: 8.5283e-04\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0085 - val_loss: 8.5985e-04\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085 - val_loss: 8.6686e-04\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0085 - val_loss: 8.7389e-04\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0084 - val_loss: 8.8092e-04\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0084 - val_loss: 8.8796e-04\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0084 - val_loss: 8.9500e-04\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0084 - val_loss: 9.0205e-04\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0084 - val_loss: 9.0909e-04\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0083 - val_loss: 9.1614e-04\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0083 - val_loss: 9.2319e-04\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0083 - val_loss: 9.3023e-04\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0083 - val_loss: 9.3729e-04\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0082 - val_loss: 9.4433e-04\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0082 - val_loss: 9.5138e-04\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0082 - val_loss: 9.5842e-04\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0082 - val_loss: 9.6545e-04\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0082 - val_loss: 9.7249e-04\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0081 - val_loss: 9.7953e-04\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0081 - val_loss: 9.8655e-04\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0081 - val_loss: 9.9357e-04\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0081 - val_loss: 0.0010\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0081 - val_loss: 0.0010\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0080 - val_loss: 0.0010\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - val_loss: 0.0010\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - val_loss: 0.0010\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0080 - val_loss: 0.0010\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0079 - val_loss: 0.0010\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0079 - val_loss: 0.0010\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0079 - val_loss: 0.0011\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0079 - val_loss: 0.0011\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0079 - val_loss: 0.0011\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0078 - val_loss: 0.0011\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0078 - val_loss: 0.0011\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0078 - val_loss: 0.0011\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0078 - val_loss: 0.0011\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0078 - val_loss: 0.0011\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0078 - val_loss: 0.0011\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0077 - val_loss: 0.0011\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - val_loss: 0.0011\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0077 - val_loss: 0.0011\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0077 - val_loss: 0.0011\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0077 - val_loss: 0.0011\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0076 - val_loss: 0.0012\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076 - val_loss: 0.0012\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0076 - val_loss: 0.0012\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0076 - val_loss: 0.0012\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0076 - val_loss: 0.0012\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0075 - val_loss: 0.0012\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0075 - val_loss: 0.0012\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0075 - val_loss: 0.0012\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0075 - val_loss: 0.0012\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0075 - val_loss: 0.0012\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0075 - val_loss: 0.0012\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0074 - val_loss: 0.0012\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0074 - val_loss: 0.0012\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0074 - val_loss: 0.0012\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - val_loss: 0.0012\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0074 - val_loss: 0.0013\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0073 - val_loss: 0.0013\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0073 - val_loss: 0.0013\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0073 - val_loss: 0.0013\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0073 - val_loss: 0.0013\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0073 - val_loss: 0.0013\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0073 - val_loss: 0.0013\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0068 - val_loss: 0.0015\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0068 - val_loss: 0.0015\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0068 - val_loss: 0.0015\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0068 - val_loss: 0.0015\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0068 - val_loss: 0.0015\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - val_loss: 0.0015\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - val_loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  \n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create the ANN model\n",
    "nn = Sequential()\n",
    "nn.add(Dense(2, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "nn.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "nn.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "# Train the model\n",
    "history = nn.fit(X_train, y_train, epochs=1000, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training history\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>I</th>\n",
       "      <th>YB</th>\n",
       "      <th>prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.774492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.757828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.744669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.738290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.726005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.723666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.719428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.703295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.688058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.682486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.681111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.68</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.674798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.654123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.653617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.652520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.640611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.630848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0.68</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.624315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.612120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.611682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.609659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.608064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.604571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.600306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.585554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        E     I    YB      prod\n",
       "999  1.00  1.00  1.00  0.774492\n",
       "998  1.00  0.89  1.00  0.757828\n",
       "989  0.89  1.00  1.00  0.744669\n",
       "899  1.00  1.00  0.89  0.738290\n",
       "988  0.89  0.89  1.00  0.726005\n",
       "997  1.00  0.68  1.00  0.723666\n",
       "898  1.00  0.89  0.89  0.719428\n",
       "889  0.89  1.00  0.89  0.703295\n",
       "987  0.89  0.68  1.00  0.688058\n",
       "888  0.89  0.89  0.89  0.682486\n",
       "897  1.00  0.68  0.89  0.681111\n",
       "979  0.68  1.00  1.00  0.674798\n",
       "996  1.00  0.30  1.00  0.654123\n",
       "799  1.00  1.00  0.68  0.653617\n",
       "978  0.68  0.89  1.00  0.652520\n",
       "887  0.89  0.68  0.89  0.640611\n",
       "798  1.00  0.89  0.68  0.630848\n",
       "879  0.68  1.00  0.89  0.624315\n",
       "986  0.89  0.30  1.00  0.612120\n",
       "995  1.00  0.09  1.00  0.611682\n",
       "789  0.89  1.00  0.68  0.609659\n",
       "977  0.68  0.68  1.00  0.608064\n",
       "896  1.00  0.30  0.89  0.604571\n",
       "878  0.68  0.89  0.89  0.600306\n",
       "797  1.00  0.68  0.68  0.585554"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_space_scaled['prod'] = nn.predict(X_test)\n",
    "comb_space_scaled.sort_values(by='prod', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# # Create an explainer\n",
    "# explainer = shap.KernelExplainer(nn.predict, X_train)\n",
    "\n",
    "# # Calculate SHAP values\n",
    "# shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# # Plot the SHAP values\n",
    "# shap.summary_plot(shap_values[0], X_train, feature_names=ENZYMES, plot_type='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Local interpretation\n",
    "# idx = 13\n",
    "# shap.force_plot(explainer.expected_value[0], shap_values[0][idx], X_train[idx], feature_names=ENZYMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the necessary packages\n",
    "# from omlt import OmltBlock, OffsetScaling\n",
    "# from omlt.io.keras import load_keras_sequential\n",
    "# from omlt.neuralnet import FullSpaceSmoothNNFormulation\n",
    "# import pyomo.environ as pyo\n",
    "\n",
    "# nn.save('reformer_nn.keras')\n",
    "\n",
    "# # first, create the Pyomo model\n",
    "# m = pyo.ConcreteModel()\n",
    "# m.reformer = OmltBlock()\n",
    "\n",
    "# nn_reformer = keras.models.load_model('reformer_nn.keras', compile=False)\n",
    "# net = load_keras_sequential(nn_reformer)\n",
    "\n",
    "# # create the variables and constraints for the neural network in Pyomo\n",
    "# m.reformer.build_formulation(FullSpaceSmoothNNFormulation(net))\n",
    "\n",
    "# solver = pyo.SolverFactory('glpk')\n",
    "# status = solver.solve(m, tee=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
