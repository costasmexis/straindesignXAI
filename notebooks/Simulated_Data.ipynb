{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dea6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (16, 11)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "from scipy.stats import qmc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from utils import plot_pca\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree unoirt DecisionTreeRegressor\n",
    "\n",
    "from straindesignxai.main import DataLoader\n",
    "\n",
    "path = \"../data/simulated/sim_data_FM_cycle1.csv\"\n",
    "data = DataLoader(path, 'y')\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_shap_values()\n",
    "data.supervised_clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1bf45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of elements in each cluster\n",
    "# print('NUMBER OF ELEMENTS IN EACH CLUSTER')\n",
    "# display(data.df['cluster'].value_counts())\n",
    "# # groupy by cluster and calculate most common values\n",
    "# print('MOST COMMON VALUES')\n",
    "# display(data.df.groupby('cluster').agg(lambda x:x.value_counts().index[0]))\n",
    "# # groupy by cluster and calculate mean values\n",
    "# print('MEAN VALUES')\n",
    "# display(data.df.groupby('cluster').mean())\n",
    "# # groupy by cluster and calculate std values\n",
    "# print('STD VALUES')\n",
    "# display(data.df.groupby('cluster').std())\n",
    "# # groupy by cluster and calculate median values\n",
    "# print('MEDIAN VALUES')\n",
    "# display(data.df.groupby('cluster').median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows in cluster 3 and 5\n",
    "df = data.df[data.df['cluster'].isin([4,5])]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b9b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_function_medium(x, dimension):\n",
    "    f = 0.0\n",
    "    for i in range(dimension):\n",
    "        f += x[i] ** 4 - 16 * x[i] ** 2 + 5 * x[i]\n",
    "\n",
    "    f *= 1 / dimension\n",
    "    return -1.0 * f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "sim_df = pd.DataFrame(columns=data.X.columns)\n",
    "for col in data.X.columns:\n",
    "    sim_df[col] = np.random.normal(df.describe()[col]['mean'], df.describe()[col]['std'], N)    \n",
    "\n",
    "sim_df['pred'] = data.model.predict(sim_df)\n",
    "sim_df.sort_values(by='pred', ascending=False, inplace=True)    \n",
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = data.X.iloc[2].values\n",
    "x = sim_df.iloc[0].values\n",
    "f=0.0\n",
    "for i in range(10):\n",
    "    f += x[i] ** 4 - 16 * x[i] ** 2 + 5 * x[i]\n",
    "f *= 1 / 10\n",
    "f = - 1 * f\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ab5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ad11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9ce88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb90f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d897e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfdfbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcbb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from scipy.stats import qmc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from utils import plot_pca\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of input variables (features)\n",
    "user_params = {\"dim\": 10}\n",
    "\n",
    "input_vars = [\"x_\" + str(i) for i in range(1, user_params[\"dim\"] + 1)]\n",
    "response_vars = [\"y\"]\n",
    "\n",
    "# Define no. of instances for the initial DBTL cycle\n",
    "user_params[\"n_instances_cycle1\"] = 100\n",
    "# Define the no. of cycles to perform\n",
    "user_params[\"num_recommendations\"] = 16\n",
    "# Define the objective for optimization and a threshold for defining success (for example, a success is 20% improvement over the best in the training data set)\n",
    "user_params[\"objective\"] = \"maximize\"\n",
    "user_params[\"threshold\"] = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a1e8d",
   "metadata": {},
   "source": [
    "### Define true response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_function_medium(x, dimension):\n",
    "    f = 0.0\n",
    "    for i in range(dimension):\n",
    "        f += x[i] ** 4 - 16 * x[i] ** 2 + 5 * x[i]\n",
    "\n",
    "    f *= 1 / dimension\n",
    "    return -1.0 * f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb28c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = user_params[\"dim\"]\n",
    "global_optimum_value = 78.332\n",
    "global_optimum = -2.903534 * np.ones(dim)\n",
    "lb, ub = -5.0, 5.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6dcb93",
   "metadata": {},
   "source": [
    "#### Define constraints on the input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = pd.DataFrame(columns=[\"Variable\", \"Min\", \"Max\", \"Scaling\"])\n",
    "bounds[\"Variable\"] = [\"x_\" + str(i) for i in range(1, dim + 1)]\n",
    "bounds[\"Min\"] = lb * np.ones(dim)\n",
    "bounds[\"Max\"] = ub * np.ones(dim)\n",
    "bounds[\"Scaling\"] = np.ones(dim)\n",
    "bounds = bounds.set_index(\"Variable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece3427",
   "metadata": {},
   "source": [
    "## Cycle 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87aae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656aa66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_cycle_data(bounds: pd.DataFrame, user_params: dict) -> pd.DataFrame:\n",
    "    \"\"\" Generate data for initial design\n",
    "\n",
    "    Args:\n",
    "        bounds (pd.DataFrame)\n",
    "        user_params (dict)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    sampler = qmc.LatinHypercube(d=user_params[\"dim\"])\n",
    "    sample = sampler.random(n=user_params[\"n_instances_cycle1\"])\n",
    "    sample = qmc.scale(sample, bounds[\"Min\"].values, bounds[\"Max\"].values)\n",
    "\n",
    "    X_initial = pd.DataFrame(sample, columns=input_vars)\n",
    "    y_initial = true_function_medium(X_initial.values.T, dim).reshape(-1, 1)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        np.hstack((X_initial, y_initial)), columns=input_vars + response_vars\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702812e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cycle 1 data from ART paper\n",
    "df = pd.read_csv(\"../data/simulated/sim_data_FM_cycle1.csv\")\n",
    "cols = df[\"Type\"].unique()\n",
    "idx = df[\"Line Name\"].unique()\n",
    "data = pd.DataFrame(columns=cols, index=idx)\n",
    "for i in idx:\n",
    "    for j in cols:\n",
    "        data.loc[i, j] = df[(df[\"Line Name\"] == i) & (df[\"Type\"] == j)][\"Value\"].values[0]\n",
    "\n",
    "data = data.astype(float)\n",
    "\n",
    "X = data.drop(\"y\", axis=1)\n",
    "y = data[\"y\"]\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf918705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and tune an XGBoost model using optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 5, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 25),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda',1e-4, 1.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    xgb = XGBRegressor(**params)\n",
    "    scores = cross_val_score(xgb, X, y, scoring='neg_mean_absolute_error', cv=3, n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "params = study.best_trial.params\n",
    "xgb_model = XGBRegressor(**params)\n",
    "xgb_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate model on the data\n",
    "def train(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=10)\n",
    "    print(f'RMSE = {np.round(np.sqrt(np.abs(scores.mean())),4)}')\n",
    "    print(f'STD = {np.round(scores.std(),4)}')\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def plot_R2(model, X, y):\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    ax.scatter(y, model.predict(X), color='blue', alpha=0.5)\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    ax.set_title('Cross Validation Predictions')\n",
    "    plt.show()\n",
    "\n",
    "xgb = train(xgb_model, X, y)\n",
    "plot_R2(xgb, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34690780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_plots(model, X):\n",
    "    # Calculate SHAP values and plot\n",
    "    explainer = shap.TreeExplainer(model, X)\n",
    "    shap_values = explainer(X)\n",
    "    shap.summary_plot(shap_values, X, plot_type='bar')\n",
    "    shap.summary_plot(shap_values, X, plot_type='dot')\n",
    "    order = np.argsort(model.predict(X))\n",
    "    shap.plots.heatmap(shap_values, instance_order=order)\n",
    "    return explainer, shap_values\n",
    "\n",
    "explainer, shap_values = shap_plots(xgb, X)\n",
    "# Shap values to dataframe\n",
    "shap_df = pd.DataFrame(shap_values.values, columns=X.columns)\n",
    "shap_df.index = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c0f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "model = KMeans(n_init='auto')\n",
    "visualizer = KElbowVisualizer(model, k=(2,10))\n",
    "visualizer.fit(shap_df)\n",
    "visualizer.show()\n",
    "\n",
    "# Get optimal number of clusters\n",
    "n_clusters = visualizer.elbow_value_\n",
    "print(f'Optimal number of clusters = {n_clusters}')\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=42).fit(shap_df)\n",
    "shap_df['Cluster'] = kmeans.labels_\n",
    "shap_df['y'] = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cluster'] = shap_df['Cluster']\n",
    "# groupy by cluster and calculate most common values\n",
    "print('MOST COMMON VALUES')\n",
    "display(data.groupby('Cluster').agg(lambda x:x.value_counts().index[0]))\n",
    "# groupy by cluster and calculate mean values\n",
    "print('MEAN VALUES')\n",
    "display(data.groupby('Cluster').mean())\n",
    "# groupy by cluster and calculate std values\n",
    "print('STD VALUES')\n",
    "display(data.groupby('Cluster').std())\n",
    "# groupy by cluster and calculate median values\n",
    "print('MEDIAN VALUES')\n",
    "display(data.groupby('Cluster').median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64514b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Cluster'] == 3].sort_values(by='y', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
